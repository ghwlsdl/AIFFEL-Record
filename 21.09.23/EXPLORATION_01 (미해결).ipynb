{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 인공지능과 가위바위보 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-1. 인공지능과 가위바위보 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 기술은 \"데이터 준비 → 딥러닝 네트워크 설계 → 학습 → 테스트(평가)\"의\n",
    "\n",
    "# 순서대로 만들게 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-2. 데이터를 준비하자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dated-parker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)   # Tensorflow의 버전을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "spatial-brunswick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "# MNIST 데이터를 로드. 다운로드하지 않았다면 다운로드까지 자동으로 진행됩니다. \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
    "\n",
    "print(len(x_train))  # x_train 배열의 크기를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "plain-candy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOR0lEQVR4nO3df6jUdb7H8df7titBrmF5klNK7l3OP7GQ2iC3jPXc9C4mkS1BKricS4XST5eMbrh/rJSBSNsSFEvuTdYTm9vSWorF7nbFiIVaG+WUVlzrhqHmjxFBkyLX9n3/ON+Wk53vZ8aZ78x39P18wDAz3/d8z/fdt159Z76f+c7H3F0Azn//UnYDADqDsANBEHYgCMIOBEHYgSC+08mNTZgwwadMmdLJTQKh7N27V0ePHrXRai2F3czmSnpS0gWS/tvdV6deP2XKFFWr1VY2CSChUqnk1pp+G29mF0h6WtKNkq6StMjMrmr27wFor1Y+s8+Q9JG7f+zupyT9XtL8YtoCULRWwn6FpH0jnu/Pln2DmS0xs6qZVWu1WgubA9CKtp+Nd/e17l5x90pPT0+7NwcgRythPyBp8ojnk7JlALpQK2F/W1KfmX3fzMZIWihpczFtASha00Nv7n7azO6V9GcND72tc/f3CusMQKFaGmd391clvVpQLwDaiK/LAkEQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxBER6dsxvlnx44dyfpTTz2VW1u/fn1y3YGBgWT9vvvuS9anT5+erEfDkR0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgmCcHUlDQ0PJ+pw5c5L1EydO5NbMLLnu4OBgsr5p06Zk/dixY8l6NC2F3cz2SvpM0leSTrt7pYimABSviCP7v7v70QL+DoA24jM7EESrYXdJfzGzHWa2ZLQXmNkSM6uaWbVWq7W4OQDNajXs17v7dEk3SrrHzH505gvcfa27V9y90tPT0+LmADSrpbC7+4Hs/oiklyTNKKIpAMVrOuxmdpGZfe/rx5J+LGl3UY0BKFYrZ+MnSnopGyv9jqTn3f1PhXSFjtm+fXuyfuuttybrx48fT9ZTY+njxo1LrjtmzJhk/ejR9CDQm2++mVu75pprWtr2uajpsLv7x5KuLrAXAG3E0BsQBGEHgiDsQBCEHQiCsANBcInreeDzzz/Pre3cuTO57uLFi5P1Tz/9tKmeGtHX15esP/TQQ8n6ggULkvWZM2fm1latWpVcd8WKFcn6uYgjOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTj7eWDp0qW5teeff76DnZydetM9nzx5MlmfNWtWsv7666/n1nbt2pVc93zEkR0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgmCc/RxQbzx6y5YtuTV3b2nb/f39yfpNN92UrD/44IO5tcsvvzy57rRp05L18ePHJ+vbtm3LrbW6X85FHNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjG2bvA0NBQsj5nzpxk/cSJE7m11JTJkjRv3rxkfcOGDcl66ppxSXrsscdya3feeWdy3Z6enmT96qvTkwin/tlfeeWV5Lr1fm9/+vTpyXo3qntkN7N1ZnbEzHaPWHaJmb1mZh9m9+lvNwAoXSNv438rae4Zyx6WtNXd+yRtzZ4D6GJ1w+7ub0g6dsbi+ZLWZ4/XS7ql2LYAFK3ZE3QT3f1g9viQpIl5LzSzJWZWNbNqrVZrcnMAWtXy2XgfvqIg96oCd1/r7hV3r9Q74QKgfZoN+2Ez65Wk7P5IcS0BaIdmw75Z0kD2eEDSpmLaAdAudcfZzWyDpH5JE8xsv6RfSFot6Q9mdoekTyTd1s4mz3V79uxJ1tesWZOsHz9+PFlPfTzq7e1NrjswMJCsjx07Nlmvdz17vXpZUnPaS9Ljjz+erHfz7/HnqRt2d1+UU5pdcC8A2oivywJBEHYgCMIOBEHYgSAIOxAEl7gW4Msvv0zWUz+nLNW/3HLcuHHJ+uDgYG6tUqkk1/3iiy+S9aj27dtXdguF48gOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewzl6Aej87XG8cvZ5Nm9I/FzBr1qyW/j5i4MgOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewzl6ABx54IFkfnjQnX39/f7LOOHpz6u33dq3brTiyA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQjLM3aMuWLbm1oaGh5LpmlqzffPPNzbSEOlL7vd6/k6lTpxbcTfnqHtnNbJ2ZHTGz3SOWrTSzA2Y2lN3mtbdNAK1q5G38byXNHWX5r9x9anZ7tdi2ABStbtjd/Q1JxzrQC4A2auUE3b1m9m72Nn983ovMbImZVc2sWqvVWtgcgFY0G/ZfS/qBpKmSDkr6Zd4L3X2tu1fcvdLT09Pk5gC0qqmwu/thd//K3f8h6TeSZhTbFoCiNRV2M+sd8fQnknbnvRZAd6g7zm5mGyT1S5pgZvsl/UJSv5lNleSS9kpa2r4Wu0NqHvNTp04l173sssuS9QULFjTV0/mu3rz3K1eubPpvz549O1lfvXp103+7W9UNu7svGmXxs23oBUAb8XVZIAjCDgRB2IEgCDsQBGEHguAS1w648MILk/Xe3t5k/XxVb2ht1apVyfqaNWuS9cmTJ+fWli9fnlx37Nixyfq5iCM7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBOHsHRP6p6NTPbNcbJ3/hhReS9fnz5yfrGzduTNaj4cgOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewzt4gd2+qJkkvv/xysv7kk08201JXeOKJJ5L1Rx99NLd2/Pjx5LqLFy9O1gcHB5N1fBNHdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgnH2BplZUzVJOnToULJ+//33J+u33357sn7ppZfm1t56663kus8991yy/s477yTr+/btS9avvPLK3NrcuXOT6959993JOs5O3SO7mU02s21m9r6ZvWdmy7Lll5jZa2b2YXY/vv3tAmhWI2/jT0ta7u5XSfo3SfeY2VWSHpa01d37JG3NngPoUnXD7u4H3X1n9vgzSR9IukLSfEnrs5etl3RLm3oEUICzOkFnZlMkTZP0N0kT3f1gVjokaWLOOkvMrGpm1Vqt1kqvAFrQcNjNbKykP0r6mbufGFnz4StBRr0axN3XunvF3Ss9PT0tNQugeQ2F3cy+q+Gg/87dv/7JzsNm1pvVeyUdaU+LAIpQd+jNhseVnpX0gbuPvJ5xs6QBSauz+01t6fA8cPr06WT96aefTtZffPHFZP3iiy/Ore3Zsye5bquuu+66ZP2GG27IrT3yyCNFt4OERsbZZ0r6qaRdZjaULVuh4ZD/wczukPSJpNva0iGAQtQNu7v/VVLet0ZmF9sOgHbh67JAEIQdCIKwA0EQdiAIwg4EwSWuDbr22mtzazNmzEiuu3379pa2Xe8S2cOHDzf9tydMmJCsL1y4MFk/l38GOxqO7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBOPsDZo0aVJubePGjbk1SXrmmWeS9dS0xq1atmxZsn7XXXcl6319fUW2gxJxZAeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIGx4MpfOqFQqXq1WO7Y9IJpKpaJqtTrqr0FzZAeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIOqG3cwmm9k2M3vfzN4zs2XZ8pVmdsDMhrLbvPa3C6BZjfx4xWlJy919p5l9T9IOM3stq/3K3R9vX3sAitLI/OwHJR3MHn9mZh9IuqLdjQEo1ll9ZjezKZKmSfpbtuheM3vXzNaZ2ficdZaYWdXMqrVarbVuATSt4bCb2VhJf5T0M3c/IenXkn4gaaqGj/y/HG09d1/r7hV3r/T09LTeMYCmNBR2M/uuhoP+O3ffKEnuftjdv3L3f0j6jaT07IYAStXI2XiT9KykD9z9iRHLe0e87CeSdhffHoCiNHI2fqakn0raZWZD2bIVkhaZ2VRJLmmvpKVt6A9AQRo5G/9XSaNdH/tq8e0AaBe+QQcEQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiio1M2m1lN0icjFk2QdLRjDZydbu2tW/uS6K1ZRfZ2pbuP+vtvHQ37tzZuVnX3SmkNJHRrb93al0RvzepUb7yNB4Ig7EAQZYd9bcnbT+nW3rq1L4nemtWR3kr9zA6gc8o+sgPoEMIOBFFK2M1srpn9r5l9ZGYPl9FDHjPba2a7smmoqyX3ss7MjpjZ7hHLLjGz18zsw+x+1Dn2SuqtK6bxTkwzXuq+K3v6845/ZjezCyTtkfQfkvZLelvSInd/v6ON5DCzvZIq7l76FzDM7EeSTkoadPcfZsvWSDrm7quz/1GOd/f/6pLeVko6WfY03tlsRb0jpxmXdIuk/1SJ+y7R123qwH4r48g+Q9JH7v6xu5+S9HtJ80voo+u5+xuSjp2xeL6k9dnj9Rr+j6XjcnrrCu5+0N13Zo8/k/T1NOOl7rtEXx1RRtivkLRvxPP96q753l3SX8xsh5ktKbuZUUx094PZ40OSJpbZzCjqTuPdSWdMM941+66Z6c9bxQm6b7ve3adLulHSPdnb1a7kw5/BumnstKFpvDtllGnG/6nMfdfs9OetKiPsByRNHvF8UrasK7j7gez+iKSX1H1TUR/+egbd7P5Iyf38UzdN4z3aNOPqgn1X5vTnZYT9bUl9ZvZ9MxsjaaGkzSX08S1mdlF24kRmdpGkH6v7pqLeLGkgezwgaVOJvXxDt0zjnTfNuEred6VPf+7uHb9JmqfhM/L/J+nnZfSQ09e/Snonu71Xdm+SNmj4bd3fNXxu4w5Jl0raKulDSf8j6ZIu6u05SbskvavhYPWW1Nv1Gn6L/q6koew2r+x9l+irI/uNr8sCQXCCDgiCsANBEHYgCMIOBEHYgSAIOxAEYQeC+H8dj1XrNRdSpAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1],cmap=plt.cm.binary) # x_train[1]에 담긴 이미지는 x_train 행렬의 2번째 이미지입니다.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "annual-appreciation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "czech-server",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50001 번째 이미지의 숫자는 바로  3 입니다.\n"
     ]
    }
   ],
   "source": [
    "# index에 0에서 59999 사이 숫자를 지정해 보세요.\n",
    "index=50000     \n",
    "plt.imshow(x_train[index],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print( (index+1), '번째 이미지의 숫자는 바로 ',  y_train[index], '입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib 이란?\n",
    "\n",
    "# 파이썬에서 제공하는 시각화(Visualization) 패키지인 Matplotlib은 차트(chart),\n",
    "\n",
    "# 플롯(plot) 등 다양한 형태로 데이터를 시각화할 수 있는 강력한 기능을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 위의 mnist.load( ) 함수를 통해 학습용 데이터 (x_train, y_train)와\n",
    "\n",
    "# 시험용 데이터 (x_test, y_test)를 나누어서 받아들이는 것을 볼 수 있는데요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "black-overview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "according-dallas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "written-ethics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0  최대값: 255\n"
     ]
    }
   ],
   "source": [
    "print('최소값:',np.min(x_train), ' 최대값:',np.max(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acute-present",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0.0  최대값: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "print('최소값:',np.min(x_train_norm), ' 최대값:',np.max(x_train_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-3. 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "boring-causing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2D\n",
    "\n",
    "Conv2D 레이어의 첫 번째 인자는 사용하는 이미지 특징의 수입니다.\n",
    "\n",
    "여기서는 16과 32를 사용했습니다.\n",
    "\n",
    "가장 먼저 16개의 이미지 특징을, 그 뒤에 32개의 이미지 특징씩을 고려하겠다는 뜻입니다.\n",
    "\n",
    "우리의 숫자 이미지는 사실 매우 단순한 형태의 이미지입니다.\n",
    "\n",
    "만약 강아지 얼굴 사진이 입력 이미지라면 훨씬 디테일하고 복잡한 영상일 것입니다.\n",
    "\n",
    "그럴 경우에는 이 특징 숫자를 늘려주는 것을 고려해 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense\n",
    "\n",
    "# Dense 레이어의 첫 번째 인자는 분류기에 사용되는 뉴런의 숫자 입니다.\n",
    "\n",
    "# 이 값이 클수록 보다 복잡한 분류기를 만들 수 있습니다.\n",
    "\n",
    "# 10개의 숫자가 아닌 알파벳을 구분하고 싶다면, 대문자 26개,\n",
    "\n",
    "# 소문자 26개로 총 52개의 클래스를 분류해 내야 합니다.\n",
    "\n",
    "# 그래서 32보다 큰 64, 128 등을 고려해 볼 수 있을 것입니다.\n",
    "\n",
    "# 마지막 Dense 레이어의 뉴런 숫자는 결과적으로 분류해 내야 하는\n",
    "\n",
    "# 클래스 수로 지정하면 됩니다.\n",
    "\n",
    "# 숫자 인식기에서는 10, 알파벳 인식기에서는 52가 되겠지요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 만든 딥러닝 네트워크 모델을 확인해 보려면, model.summary() 메소드를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "musical-voice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 30,762\n",
      "Trainable params: 30,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-4. 딥러닝 네트워크 학습시키기\n",
    "\n",
    "# 네트워크의 입력은 (데이터갯수, 이미지 크기 x, 이미지 크기 y, 채널수) 와 같은 형태를 가집니다.\n",
    "\n",
    "# 이전 스텝에서 첫 번째 레이어에 input_shape=(28,28,1)로 지정하였으므로,\n",
    "\n",
    "# print(x_train.shape) 을 해보면,(60000, 28, 28) 로 채널수에 대한 정보가 없습니다. 따라서 (60000, 28, 28, 1) 로 만들어 주어야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "virgin-reservoir",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Reshape - x_train_norm shape: (60000, 28, 28)\n",
      "Before Reshape - x_test_norm shape: (10000, 28, 28)\n",
      "After Reshape - x_train_reshaped shape: (60000, 28, 28, 1)\n",
      "After Reshape - x_test_reshaped shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 1)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 1)\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "delayed-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 13s 5ms/step - loss: 0.4313 - accuracy: 0.8688\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0721 - accuracy: 0.9790\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0471 - accuracy: 0.9852\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0376 - accuracy: 0.9883\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0290 - accuracy: 0.9911\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0269 - accuracy: 0.9915\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0196 - accuracy: 0.9938\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0164 - accuracy: 0.9940\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0125 - accuracy: 0.9959\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0117 - accuracy: 0.9961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f60e28d5bd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 내용을 기반으로 x_train 학습 데이터로 딥러닝 네트워크를 학습\n",
    "\n",
    "# epochs=10 은 전체 60,000개의 데이터를 10번 반복 사용해서 학습을 시키라는 뜻\n",
    "\n",
    "# model의 입력 정의에 형태를 맞춘 x_train_reshaped가 사용해야함.\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 학습이 진행됨에 따라 epoch 별로 어느 정도 인식 정확도(accuracy)가 올라가는지 확인할 수 있습니다.\n",
    "\n",
    "# 인식 정확도가 0.8688에서 0.9961까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-5. 얼마나 잘 만들었는지 확인하기\n",
    "\n",
    "# 위의 인식 정확도는 학습용 데이터(x_train)을 가지고 구한 것입니다.\n",
    "\n",
    "# 즉, 연습문제를 잘푸는 인공지능을 만든 거죠.\n",
    "\n",
    "# 우리가 만든 딥러닝 네트워크는 실제 시험도의 결과를 알기 위해서,\n",
    "\n",
    "# 시험용 데이터(x_test)를 가지고 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "elder-tiger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.0377 - accuracy: 0.9893\n",
      "test_loss: 0.03768241032958031 \n",
      "test_accuracy: 0.989300012588501\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 학습한 대로 결과값이 99.61 점이 나올 거라 예상을 하였으나,\n",
    "\n",
    "# 결과적으로 98.93 점이 나옴을 확인 할 수 있었습니다.\n",
    "\n",
    "# 즉, 연습문제보다, 실제 시험 문제가 어렵다라는 것을 알 수 있으며,\n",
    "\n",
    "# 어찌보면, 인식률이 떨어지는 것은 당연하다고 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-6. 더 좋은 네트워크 만들어 보기\n",
    "\n",
    "# 3번째 스텝에서 진행한, 딥러닝 네트워크 설계하기에서 살펴본\n",
    "\n",
    "# 하이퍼파라미터들을 바꾸어 보는 것인데요.\n",
    "\n",
    "# Conv2D 레이어에서 입력 이미지의 특징 수를 늘리거나 줄여 보거나,\n",
    "\n",
    "# Dense 레이어에서 뉴런수를 바꾸어 보거나,\n",
    "\n",
    "# 학습 반복 횟수인 epoch 값을 변경해 볼 수 있을 겁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-7. 미니 프로젝트 : 가위바위보 분류기를 만들자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 setup 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "level-garlic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "independent-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 + Resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "alleged-token",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "proprietary-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "monetary-rainbow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111  images to be resized.\n",
      "111  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "corresponding-slope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101  images to be resized.\n",
      "101  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "essential-zoning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102  images to be resized.\n",
      "102  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "indoor-cassette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 314 입니다.\n",
      "최소값: 0  최대값: 255\n",
      "최소값: 0.0  최대값: 1.0\n",
      "x_train shape: (314, 28, 28, 3)\n",
      "y_train shape: (314,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=314):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "print('최소값:',np.min(x_train), ' 최대값:',np.max(x_train))\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "print('최소값:',np.min(x_train_norm), ' 최대값:',np.max(x_train_norm))\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "gothic-viewer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "hairy-atlantic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  images to be resized.\n",
      "0  images resized.\n",
      "rock_test 이미지 resize 완료!\n",
      "0  images to be resized.\n",
      "0  images resized.\n",
      "scissor_test 이미지 resize 완료!\n",
      "0  images to be resized.\n",
      "0  images resized.\n",
      "paepr_test 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock_test\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"rock_test 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor_test\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"scissor_test 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper_test\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"paepr_test 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "italian-casting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 0 입니다.\n",
      "최소값: 0  최대값: 0\n",
      "최소값: 0.0  최대값: 0.0\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "print('최소값:',np.min(x_test), ' 최대값:',np.max(x_test))\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "print('최소값:',np.min(x_test_norm), ' 최대값:',np.max(x_test_norm))\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "unusual-proceeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 314 입니다.\n",
      "최소값: 0  최대값: 255\n",
      "최소값: 0.0  최대값: 1.0\n",
      "x_test shape: (314, 28, 28, 3)\n",
      "y_test shape: (314,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=314):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "print('최소값:',np.min(x_test), ' 최대값:',np.max(x_test))\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "print('최소값:',np.min(x_test_norm), ' 최대값:',np.max(x_test_norm))\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "precious-snowboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 225,610\n",
      "Trainable params: 225,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.7277 - accuracy: 0.2628\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0593 - accuracy: 0.3480\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8708 - accuracy: 0.5884\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8308 - accuracy: 0.5023\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.7554\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8765\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.9530\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2004 - accuracy: 0.9654\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9675\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9811\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9898\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9855\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1036 - accuracy: 0.9656\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0761 - accuracy: 0.9789\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9826\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.9845\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.9909\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9842\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9967\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f609cdce1d0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=128\n",
    "n_test_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_test_norm, y_test, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "raising-brave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "test_loss: 0.0 \n",
      "test_accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "downtown-manhattan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.predict() 결과 :  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "model이 추론한 가장 가능성이 높은 결과 :  0\n",
      "실제 데이터의 라벨 :  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_result = model.predict(x_test)  # model이 추론한 확률값. \n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "idx=0  #1번째 x_test를 살펴보자. \n",
    "print('model.predict() 결과 : ', predicted_result[idx])\n",
    "print('model이 추론한 가장 가능성이 높은 결과 : ', predicted_labels[idx])\n",
    "print('실제 데이터의 라벨 : ', y_test[idx])\n",
    "plt.imshow(x_test[idx],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "irish-marathon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘 못 분류한 테스트 데이터 수 : 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-a1e62777bfc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"잘 못 분류한 테스트 데이터 수 :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrong_predict_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# wrong_predict_list 에서 랜덤하게 5개만 뽑아봅시다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwrong_predict_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/random.py\u001b[0m in \u001b[0;36mchoices\u001b[0;34m(self, population, weights, cum_weights, k)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0m_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0mcum_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_itertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/random.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0m_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0mcum_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_itertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "wrong_predict_list=[]\n",
    "for i, _ in enumerate(predicted_labels):\n",
    "    # i번째 test_labels과 y_test이 다른 경우만 모아 봅시다. \n",
    "    if predicted_labels[i] != y_test[i]:\n",
    "        wrong_predict_list.append(i)\n",
    "\n",
    "print(\"잘 못 분류한 테스트 데이터 수 :\", len(wrong_predict_list))\n",
    "# wrong_predict_list 에서 랜덤하게 5개만 뽑아봅시다.\n",
    "samples = random.choices(population=wrong_predict_list, k=5)\n",
    "\n",
    "for n in samples:\n",
    "    print(\"예측확률분포: \" + str(predicted_result[n]))\n",
    "    print(\"라벨: \" + str(y_test[n]) + \", 예측결과: \" + str(predicted_labels[n]))\n",
    "    plt.imshow(x_test[n], cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-seminar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
