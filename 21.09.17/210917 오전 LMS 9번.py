# Preview

# Q. ë°ì´í„° ì „ì²˜ë¦¬ëŠ” ì™œ í•´ì•¼í• ê¹Œìš”??

# ë™í˜„ : ê²°ê³¼ê°’ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ” ì˜ëª»ëœ ë°ì´í„°ë¥¼ ì§€ì›Œì•¼ í•œë‹¤.

# í˜¸ì§„ : ë°ì´í„°ê°€ ë„ˆë¬´ ë§ì„ ë•Œ ì§„ì§œë¡œ í•„ìš”í•œ ë°ì´í„°ë§Œ ì¶”ì¶œí•´ì•¼ í•œë‹¤.

# íƒœê·  : ë°ì´í„°ì— ê²°ì¸¡ê°’ì„ ì²˜ë¦¬í•´ì£¼ê¸° ìœ„í•´ì„œ í•„ìš”í•˜ë‹¤.

# ì„±ì—° : ë¶„ì„ì˜ ê²°ê³¼ì— ì‹ ë¢°ë„ë¥¼ ì¢Œìš°í•˜ëŠ”ê²Œ ë°ì´í„° ì „ì²˜ë¦¬ë¼ê³  ìƒê°í•œë‹¤.

# ë¨¸ì‹ ëŸ¬ë‹ : ê¸°ê³„ë¥¼ í•™ìŠµì‹œí‚¨ë‹¤ëŠ” ê²ƒì¸ë°,

# ê¸°ê³„ë¼ëŠ” ê²ƒì€ ê²°êµ­ í™•ë¥  ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ë‹¤.

# í•™ìŠµì„ í†µí•´ ì–»ì€ í™•ë¥ ëª¨ë¸ì„ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ì„œë„ ê³„ì† ì‚¬ìš©ì„ í•©ë‹ˆë‹¤.

# ê²°êµ­ì€ ëª¨ë¸ì˜ ì •í™•ë„ì™€ ì‹ ë¢°ë„ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ì£¼ëŠ”ê²Œ ë°ì´í„° ì „ì²˜ë¦¬ì…ë‹ˆë‹¤.


# In[ ]:


# ë°ì´í„° ë¶„ì„ì˜ 8í• ì€ ë°ì´í„° ì „ì²˜ë¦¬ì´ë‹¤. ë¼ëŠ” ë§ì´ ìˆëŠ”ë°,

# ì¤‘ìš”í•œ ì´ìœ ëŠ”, ë°ì´í„° ë¶„ì„ì˜ ì§ˆì´ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.


# In[1]:


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
print("ğŸ‘½ Hello.")


# In[2]:


import os

csv_file_path = os.getenv('HOME')+'/aiffel/data_preprocess/data/trade.csv'
trade = pd.read_csv(csv_file_path) 
trade.head()


# In[ ]:


#ì¤‘ë³µëœ ë°ì´í„°ë¥¼ ì°¾ì•„ ì œê±°í•  ìˆ˜ ìˆê³ , ê²°ì¸¡ì¹˜(missing data)ë¥¼ ì œê±°í•˜ê±°ë‚˜ ì±„ì›Œ ë„£ì„ ìˆ˜ ìˆë‹¤.

# ë°ì´í„°ë¥¼ ì •ê·œí™”ì‹œí‚¬ ìˆ˜ ìˆë‹¤.

# ì´ìƒì¹˜(outlier)ë¥¼ ì°¾ê³ , ì´ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.

# ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ì›-í•« ì¸ì½”ë”©í•  ìˆ˜ ìˆë‹¤.

# ì—°ì†ì ì¸ ë°ì´í„°ë¥¼ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ  ë²”ì£¼í˜• ë°ì´í„°ë¡œ ë³€í™˜í•  ìˆ˜ ìˆë‹¤.


# In[ ]:


# ê²°ì¸¡ì¹˜(Missing Data)

# ì¤‘ë³µëœ ë°ì´í„°

# ì´ìƒì¹˜(Outlier)

# ì •ê·œí™”(Normalization)

# ì›-í•« ì¸ì½”ë”©(One-Hot Encoding)

# êµ¬ê°„í™”(Binning)


# In[ ]:


# 9-2. ê²°ì¸¡ì¹˜


# In[3]:


print('ì „ì²´ ë°ì´í„° ê±´ìˆ˜:', len(trade))


# In[4]:


print('ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ê°œìˆ˜')
len(trade) - trade.count()


# In[5]:


trade = trade.drop('ê¸°íƒ€ì‚¬í•­', axis=1)
trade.head()


# In[ ]:


# DataFrame.isnull()ì€ ë°ì´í„°ë§ˆë‹¤ ê²°ì¸¡ì¹˜ ì—¬ë¶€ë¥¼

# True, Falseë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

# DataFrame.any(axis=1)ëŠ” í–‰ë§ˆë‹¤ í•˜ë‚˜ë¼ë„ Trueê°€ ìˆìœ¼ë©´ True,

# ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ Falseë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.


# In[ ]:


# DataFrameì— isnull()ì„ ì ìš©í•˜ê³ ,

# ì—¬ê¸°ë„ ë˜ any(axis=1) ë©”ì„œë“œë¥¼ ì ìš©í•©ë‹ˆë‹¤.

# ì´ ê²°ê³¼, 'ê° í–‰ì´ ê²°ì¸¡ì¹˜ê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€' ì—¬ë¶€ë¥¼

# ë¶ˆë¦¬ì–¸ ê°’ìœ¼ë¡œ ê°€ì§„ Seriesê°€ ì¶œë ¥ë©ë‹ˆë‹¤.


# In[6]:


trade.isnull() # isnull ì€ ê²°ì¸¡ì¹˜ì˜ ì—¬ë¶€ë¥¼ ì¸¡ì • í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


# In[7]:


trade.isnull().any(axis=1)


# In[8]:


trade[trade.isnull().any(axis=1)]


# In[ ]:


# DataFrameì˜ dropnaëŠ” ê²°ì¸¡ì¹˜ë¥¼ ì‚­ì œí•´ì£¼ëŠ” ë©”ì„œë“œì…ë‹ˆë‹¤.

# subset ì˜µì…˜ìœ¼ë¡œ íŠ¹ì • ì»¬ëŸ¼ë“¤ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤.

# how ì˜µì…˜ìœ¼ë¡œ ì„ íƒí•œ ì»¬ëŸ¼ ì „ë¶€ê°€ ê²°ì¸¡ì¹˜ì¸

# í–‰ì„ ì‚­ì œí•˜ê² ë‹¤ëŠ” ì˜ë¯¸ë¡œ 'all'ì„ ì„ íƒí•©ë‹ˆë‹¤.

# ('any': í•˜ë‚˜ë¼ë„ ê²°ì¸¡ì¹˜ì¸ ê²½ìš°)

# * inplace ì˜µì…˜ìœ¼ë¡œ í•´ë‹¹ DataFrame ë‚´ë¶€ì— ë°”ë¡œ ì ìš©ì‹œì¼°ìŠµë‹ˆë‹¤.


# In[9]:


trade.dropna(how='all', subset=['ìˆ˜ì¶œê±´ìˆ˜', 'ìˆ˜ì¶œê¸ˆì•¡', 'ìˆ˜ì…ê±´ìˆ˜', 'ìˆ˜ì…ê¸ˆì•¡', 'ë¬´ì—­ìˆ˜ì§€'], inplace=True)
print("ğŸ‘½ It's okay, no biggie.")


# In[10]:


trade[trade.isnull().any(axis=1)]


# In[11]:


trade.loc[[188, 191, 194]]


# In[12]:


trade.loc[191, 'ìˆ˜ì¶œê¸ˆì•¡'] = (trade.loc[188, 'ìˆ˜ì¶œê¸ˆì•¡'] + trade.loc[194, 'ìˆ˜ì¶œê¸ˆì•¡'] )/2
trade.loc[[191]]


# In[13]:


trade.loc[191, 'ë¬´ì—­ìˆ˜ì§€'] = trade.loc[191, 'ìˆ˜ì¶œê¸ˆì•¡'] - trade.loc[191, 'ìˆ˜ì…ê¸ˆì•¡'] 
trade.loc[[191]]


# In[ ]:


# 9-3. ì¤‘ë³µëœ ë°ì´í„°


# In[14]:


#DataFrame.duplicated()ëŠ” ì¤‘ë³µëœ ë°ì´í„° ì—¬ë¶€ë¥¼ ë¶ˆë¦¬ì–¸ ê°’ìœ¼ë¡œë°˜í™˜

trade.duplicated()


# In[15]:


trade[trade.duplicated()]


# In[16]:


trade[(trade['ê¸°ê°„']=='2020ë…„ 03ì›”')&(trade['êµ­ê°€ëª…']=='ì¤‘êµ­')]


# In[17]:


trade.drop_duplicates(inplace=True)
print("ğŸ‘½ It's okay, no biggie.")


# In[18]:


df = pd.DataFrame({'id':['001', '002', '003', '004', '002'], 
                   'name':['Park Yun', 'Kim Sung', 'Park Jin', 'Lee Han', 'Kim Min']})
df


# In[19]:


df.drop_duplicates(subset=['id'], keep='last')


# In[ ]:


# pandas.DataFrame.drop_duplicates'

# subset : ì—´ ë ˆì´ë¸” ë˜ëŠ” ë ˆì´ë¸” ì‹œí€€ìŠ¤, ì„ íƒ ì‚¬í•­

# ì¤‘ë³µì„ ì‹ë³„í•˜ê¸° ìœ„í•´ íŠ¹ì • ì—´ë§Œ ê³ ë ¤í•˜ê³  ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  ì—´ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

# keep : ì²« ë²ˆì§¸'{ 'ì²« ë²ˆì§¸' 'ë§ˆì§€ë§‰', ê±°ì§“}, ê¸°ë³¸

# ìœ ì§€í•  ë³µì œë³¸(ìˆëŠ” ê²½ìš°)ì„ ê²°ì •í•©ë‹ˆë‹¤.

# - first: ì²« ë²ˆì§¸ í•­ëª©ì„ ì œì™¸í•˜ê³  ì¤‘ë³µ í•­ëª©ì„ ì‚­ì œí•©ë‹ˆë‹¤.

# - last: ë§ˆì§€ë§‰ í•­ëª©ì„ ì œì™¸í•˜ê³  ì¤‘ë³µ í•­ëª©ì„ ì‚­ì œí•©ë‹ˆë‹¤.

# - False : ëª¨ë“  ì¤‘ë³µì„ ì‚­ì œí•©ë‹ˆë‹¤.

# inplace : bool, ê¸°ë³¸ê°’ False

# ë³µì œë³¸ì„ ì œìë¦¬ì— ì‚­ì œí• ì§€ ë˜ëŠ” ë³µì‚¬ë³¸ì„ ë°˜í™˜í• ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤.

# ignore_index : bool, ê¸°ë³¸ê°’ì€ False

# Trueì´ë©´ ê²°ê³¼ ì¶•ì— 0, 1, ..., n - 1ì´ë¼ëŠ” ë ˆì´ë¸”ì´ ì§€ì •ë©ë‹ˆë‹¤.

# ì¤‘ë³µì´ ì œê±°ëœ DataFrame ë˜ëŠ” None ê²½ìš° inplace=True.


# In[20]:


df = pd.DataFrame({
    'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],
    'style': ['cup', 'cup', 'cup', 'pack', 'pack'],
    'rating': [4, 4, 3.5, 15, 5]
})
df


# In[21]:


# ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  ì—´ì„ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ë³µ í–‰ì„ ì œê±°í•©ë‹ˆë‹¤.

df.drop_duplicates()


# In[22]:


# íŠ¹ì • ì—´ì—ì„œ ì¤‘ë³µì„ ì œê±°í•˜ë ¤ë©´ subset ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

df.drop_duplicates(subset=['brand'])


# In[23]:


# ì¤‘ë³µì„ ì œê±°í•˜ê³  ë§ˆì§€ë§‰ í•­ëª©ì„ ìœ ì§€í•˜ë ¤ë©´ ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤

df.drop_duplicates(subset=['brand', 'style'], keep='last') 


# In[ ]:


# 9.4. ì´ìƒì¹˜(Outier) :

# ëŒ€ë¶€ë¶„ ê°’ì˜ ë²”ìœ„ì—ì„œ ë²—ì–´ë‚˜ ê·¹ë‹¨ì ìœ¼ë¡œ í¬ê±°ë‚˜ ì‘ì€ ê²‚ì„ ì˜ë¯¸

# Min-Max Scaling í•´ë³´ë©´ ëŒ€ë¶€ë¶„ì˜ ê°’ì€ 0ì— ê°€ê¹ê³  ì´ìƒì¹˜ë§Œ 1ì— ê°€ê¹Œìš´ ê°’ì„ ê°€ì§€ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.

# í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ì´ìš©í•˜ëŠ” z score

# í‰ê· ì„ ë¹¼ì£¼ê³  í‘œì¤€í¸ì°¨ë¡œ ë‚˜ëˆ  z score({\frac {X-\mu }{\sigma }})( )ë¥¼ ê³„ì‚°


# In[24]:


def outlier(df, col, z):
    return df[abs(df[col] - np.mean(df[col]))/np.std(df[col])>z].index
print("ğŸ‘½ It's okay, no biggie.")


# In[ ]:


# z-score method

# abs(df[col] - np.mean(df[col])) :
# ë°ì´í„°ì—ì„œ í‰ê· ì„ ë¹¼ì¤€ ê²ƒì— ì ˆëŒ€ê°’ì„ ì·¨í•©ë‹ˆë‹¤.
# abs(df[col] - np.mean(df[col]))/np.std(df[col]) :
# ìœ„ì— í•œ ì‘ì—…ì— í‘œì¤€í¸ì°¨ë¡œ ë‚˜ëˆ ì¤ë‹ˆë‹¤.
# df[abs(df[col] - np.mean(df[col]))/np.std(df[col])>z].index:
# ê°’ì´ zë³´ë‹¤ í° ë°ì´í„°ì˜ ì¸ë±ìŠ¤ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.


# In[25]:


trade.loc[outlier(trade, 'ë¬´ì—­ìˆ˜ì§€', 1.5)]


# In[27]:


trade.loc[outlier(trade, 'ë¬´ì—­ìˆ˜ì§€', 2)]


# In[28]:


trade.loc[outlier(trade, 'ë¬´ì—­ìˆ˜ì§€', 3)]


# In[29]:


def not_outlier(df, col, z):
    return df[abs(df[col] - np.mean(df[col]))/np.std(df[col]) <= z].index
print("ğŸ‘½ It's okay, no biggie.")


# In[30]:


trade.loc[not_outlier(trade, 'ë¬´ì—­ìˆ˜ì§€', 1.5)]


# In[31]:


# IQR method

np.random.seed(2020)
data = np.random.randn(100)  # í‰ê·  0, í‘œì¤€í¸ì°¨ 1ì˜ ë¶„í¬ì—ì„œ 100ê°œì˜ ìˆ«ìë¥¼ ìƒ˜í”Œë§í•œ ë°ì´í„° ìƒì„±
data = np.concatenate((data, np.array([8, 10, -3, -5])))      # [8, 10, -3, -5])ë¥¼ ë°ì´í„° ë’¤ì— ì¶”ê°€í•¨
data


# In[32]:


fig,ax = plt.subplots()
ax.boxplot(data)
plt.show()


# In[33]:


Q3,Q1 = np.percentile(data, [75,25])
IQR = Q3 - Q1
IQR


# In[34]:


data[(Q1-1.5*IQR > data)|(Q3+1.5*IQR < data)]


# In[35]:


# Z-score method

import numpy as np

def outliers_z_score(ys):
    threshold = 3

    mean_y = np.mean(ys)
    stdev_y = np.std(ys)
    z_scores = [(y - mean_y) / stdev_y for y in ys]
    return np.where(np.abs(z_scores) > threshold)


# In[36]:


import numpy as np

def outliers_modified_z_score(ys):
    threshold = 3.5

    median_y = np.median(ys)
    median_absolute_deviation_y = np.median([np.abs(y - median_y) for y in ys])
    modified_z_scores = [0.6745 * (y - median_y) / median_absolute_deviation_y
                         for y in ys]
    return np.where(np.abs(modified_z_scores) > threshold)


# In[37]:


import numpy as np

def outliers_iqr(ys):
    quartile_1, quartile_3 = np.percentile(ys, [25, 75])
    iqr = quartile_3 - quartile_1
    lower_bound = quartile_1 - (iqr * 1.5)
    upper_bound = quartile_3 + (iqr * 1.5)
    return np.where((ys > upper_bound) | (ys < lower_bound))


# In[42]:


def outlier2(df, col):
    # [[YOUR CODE]]

outlier2(trade, 'ë¬´ì—­ìˆ˜ì§€') pass


# In[43]:


# ì •ê·œë¶„í¬ë¥¼ ë”°ë¼ ëœë¤í•˜ê²Œ ë°ì´í„° xë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

np.random.seed(2020)
x = pd.DataFrame({'A': np.random.randn(100)*4+4,
                 'B': np.random.randn(100)-1})
x


# In[44]:


# ë°ì´í„° xë¥¼ Standardization ê¸°ë²•ìœ¼ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤. 

x_standardization = (x - x.mean())/x.std()
x_standardization


# In[45]:


# ë°ì´í„° xë¥¼ min-max scaling ê¸°ë²•ìœ¼ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤. 

x_min_max = (x-x.min())/(x.max()-x.min())
x_min_max


# In[46]:


fig, axs = plt.subplots(1,2, figsize=(12, 4),
                        gridspec_kw={'width_ratios': [2, 1]})

axs[0].scatter(x['A'], x['B'])
axs[0].set_xlim(-5, 15)
axs[0].set_ylim(-5, 5)
axs[0].axvline(c='grey', lw=1)
axs[0].axhline(c='grey', lw=1)
axs[0].set_title('Original Data')

axs[1].scatter(x_standardization['A'], x_standardization['B'])
axs[1].set_xlim(-5, 5)
axs[1].set_ylim(-5, 5)
axs[1].axvline(c='grey', lw=1)
axs[1].axhline(c='grey', lw=1)
axs[1].set_title('Data after standardization')

plt.show()


# In[47]:


fig, axs = plt.subplots(1,2, figsize=(12, 4),
                        gridspec_kw={'width_ratios': [2, 1]})

axs[0].scatter(x['A'], x['B'])
axs[0].set_xlim(-5, 15)
axs[0].set_ylim(-5, 5)
axs[0].axvline(c='grey', lw=1)
axs[0].axhline(c='grey', lw=1)
axs[0].set_title('Original Data')

axs[1].scatter(x_min_max['A'], x_min_max['B'])
axs[1].set_xlim(-5, 5)
axs[1].set_ylim(-5, 5)
axs[1].axvline(c='grey', lw=1)
axs[1].axhline(c='grey', lw=1)
axs[1].set_title('Data after min-max scaling')

plt.show()


# In[48]:


# Standardization


# In[49]:


# trade ë°ì´í„°ë¥¼ Standardization ê¸°ë²•ìœ¼ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.

cols = ['ìˆ˜ì¶œê±´ìˆ˜', 'ìˆ˜ì¶œê¸ˆì•¡', 'ìˆ˜ì…ê±´ìˆ˜', 'ìˆ˜ì…ê¸ˆì•¡', 'ë¬´ì—­ìˆ˜ì§€']
trade_Standardization= (trade[cols]-trade[cols].mean())/trade[cols].std()
trade_Standardization.head()


# In[50]:


trade_Standardization.describe()


# In[51]:


# trade ë°ì´í„°ë¥¼ min-max scaling ê¸°ë²•ìœ¼ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤. 

trade[cols] = (trade[cols]-trade[cols].min())/(trade[cols].max()-trade[cols].min())
trade.head()


# In[52]:


trade.describe()


# In[53]:


train = pd.DataFrame([[10, -10], [30, 10], [50, 0]])
test = pd.DataFrame([[0, 1], [10, 10]])
print("ğŸ‘½ It's okay, no biggie.")


# In[54]:


train_min = train.min()
train_max = train.max()

train_min_max = (train - train_min)/(train_max - train_min)
test_min_max =  (test - train_min)/(train_max - train_min)    # testë¥¼ min-max scalingí•  ë•Œë„ train ì •ê·œí™” ê¸°ì¤€ìœ¼ë¡œ ìˆ˜í–‰
print("ğŸ’« It's okay, no biggie...")


# In[55]:


train_min_max


# In[56]:


test_min_max


# In[57]:


from sklearn.preprocessing import MinMaxScaler
train = [[10, -10], [30, 10], [50, 0]]
test = [[0, 1]]
scaler = MinMaxScaler()
print("ğŸ‘½ It's okay, no biggie.")


# In[58]:


scaler.fit_transform(train)


# In[59]:


scaler.transform(test)


# In[ ]:


# 9-6. ì›-í•« ì¸ì½”ë”©(One-Hot Encoding)


# In[60]:


#trade ë°ì´í„°ì˜ êµ­ê°€ëª… ì»¬ëŸ¼ ì›ë³¸
print(trade['êµ­ê°€ëª…'].head())  

# get_dummiesë¥¼ í†µí•´ êµ­ê°€ëª… ì›-í•« ì¸ì½”ë”©
country = pd.get_dummies(trade['êµ­ê°€ëª…'])
country.head()


# In[61]:


#trade ë°ì´í„°ì˜ êµ­ê°€ëª… ì»¬ëŸ¼ ì›ë³¸
print(trade['êµ­ê°€ëª…'].head())  

# get_dummiesë¥¼ í†µí•´ êµ­ê°€ëª… ì›-í•« ì¸ì½”ë”©
country = pd.get_dummies(trade['êµ­ê°€ëª…'])
country.head()


# In[62]:


trade.drop(['êµ­ê°€ëª…'], axis=1, inplace=True)
trade.head()


# In[ ]:


# 9-7. êµ¬ê°„í™”(Binning)


# In[63]:


salary = pd.Series([4300, 8370, 1750, 3830, 1840, 4220, 3020, 2290, 4740, 4600, 
                    2860, 3400, 4800, 4470, 2440, 4530, 4850, 4850, 4760, 4500, 
                    4640, 3000, 1880, 4880, 2240, 4750, 2750, 2810, 3100, 4290, 
                    1540, 2870, 1780, 4670, 4150, 2010, 3580, 1610, 2930, 4300, 
                    2740, 1680, 3490, 4350, 1680, 6420, 8740, 8980, 9080, 3990, 
                    4960, 3700, 9600, 9330, 5600, 4100, 1770, 8280, 3120, 1950, 
                    4210, 2020, 3820, 3170, 6330, 2570, 6940, 8610, 5060, 6370,
                    9080, 3760, 8060, 2500, 4660, 1770, 9220, 3380, 2490, 3450, 
                    1960, 7210, 5810, 9450, 8910, 3470, 7350, 8410, 7520, 9610, 
                    5150, 2630, 5610, 2750, 7050, 3350, 9450, 7140, 4170, 3090])
print("ğŸ‘½ Almost there..")


# In[64]:


salary.hist()


# In[65]:


bins = [0, 2000, 4000, 6000, 8000, 10000]
print("ğŸ‘½ Almost there..")


# In[66]:


ctg = pd.cut(salary, bins=bins)
ctg


# In[67]:


print('salary[0]:', salary[0])
print('salary[0]ê°€ ì†í•œ ì¹´í…Œê³ ë¦¬:', ctg[0])


# In[68]:


ctg.value_counts().sort_index()


# In[69]:


ctg = pd.cut(salary, bins=6)
ctg


# In[70]:


ctg.value_counts().sort_index()


# In[73]:


ctg = pd.qcut(salary, q=5)
ctg


# In[74]:


print(ctg.value_counts().sort_index())
print(".\n.\nğŸ›¸ Well done!")


# In[ ]:




